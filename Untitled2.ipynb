{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdCOTtHwDZlZbi4aog0dBw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoosufcancode/machinelearningCW/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset\n",
        "\n",
        "We are preparing our environment to load the dataset required for our income classification challenge in this first stage. We're mounting the disk using Google Colab's features, which enables us to access files from our Google disk straight from this notebook. As a result, loading the Census Income dataset for preprocessing and analysis will go more smoothly.\n",
        "\n"
      ],
      "metadata": {
        "id": "cG0NhW434Wdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4PAFrAUCVtu",
        "outputId": "b373ffca-5051-4ab2-a261-cde8dbb9762c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#Loading the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specifying Dataset and Metadata Paths\n",
        "\n",
        "We now specify the paths to the dataset and metadata files after mounting our Google Drive. We can be sure we have structured access to all required files because the paths for the training data, test data, index, and metadata have been defined. In order to properly load the data in the following steps for our machine learning work, these paths indicate where the files are placed within the Google Drive directory structure.\n",
        "\n"
      ],
      "metadata": {
        "id": "XgEr5QDs4jDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the dataset file\n",
        "train_data_path = '/content/drive/My Drive/ML_CW_DATASET/adult.data'\n",
        "\n",
        "metadata1_path = '/content/drive/My Drive/ML_CW_DATASET/adult.names'\n",
        "\n",
        "test_data_path = '/content/drive/My Drive/ML_CW_DATASET/adult.test'\n",
        "\n",
        "index_path = '/content/drive/My Drive/ML_CW_DATASET/index'\n",
        "\n",
        "metadata2_path = '/content/drive/My Drive/ML_CW_DATASET/old.adult.names'"
      ],
      "metadata": {
        "id": "NVOzhn_YJ9zR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Libraries\n",
        "\n",
        "Before we start analyzing and processing our data, we need to import several key Python libraries:\n",
        "\n",
        "- `pandas`: Essential for data manipulation and analysis.\n",
        "- `sklearn.model_selection`: Contains functions like `train_test_split` to divide our data into training and test sets.\n",
        "- `sklearn.preprocessing`: Provides the `OneHotEncoder` for converting categorical variables into a form that could be provided to ML algorithms.\n",
        "- `sklearn.naive_bayes`: Includes the `GaussianNB` classifier which is the Naïve Bayes algorithm for classification tasks.\n",
        "- `sklearn.ensemble`: From this module, we are using the `RandomForestClassifier` for building a more complex model than Naïve Bayes.\n",
        "- `sklearn.metrics`: It provides functions to assess the accuracy and performance of our models such as `accuracy_score` and `classification_report`.\n",
        "\n",
        "These libraries will provide the necessary tools to preprocess the data, train the classification models, and evaluate their performance.\n"
      ],
      "metadata": {
        "id": "xmIWmqTL44F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "2cL8hEX-CsmP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Column Names and Loading the Data\n",
        "\n",
        "Since column headers are absent from the dataset, we begin by defining the `column_names` using the metadata included in the `adult.names` file. The target variable and attributes that we will utilize to predict revenue are reflected in these names.\n",
        "\n",
        "After defining the column names, we use the robust data manipulation tool `pandas` to load the training set of data. After reading the CSV file, we assigned the headers based on the list of `column_names`. Lastly, we use `df.head()` to show the first few rows of our dataframe in order to confirm that the columns have been named appropriately and the data has been loaded correctly. In order to properly prepare our dataframe for the upcoming data preparation and analysis, this step guarantees it.\n",
        "\n"
      ],
      "metadata": {
        "id": "9Qzq_PhK5oOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# column names from 'adult.names' file\n",
        "column_names = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
        "    'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
        "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
        "    'income'\n",
        "]\n",
        "\n",
        "# Loading the data\n",
        "df = pd.read_csv(train_data_path, header=None, names=column_names)\n",
        "\n",
        "# Checking the first few rows to ensure it's loaded correctly\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "6Mz-Xv1i8lpC",
        "outputId": "53cfd592-7df5-44c7-c79f-30226600c7e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age          workclass  fnlwgt   education  education_num  \\\n",
              "0   39          State-gov   77516   Bachelors             13   \n",
              "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
              "2   38            Private  215646     HS-grad              9   \n",
              "3   53            Private  234721        11th              7   \n",
              "4   28            Private  338409   Bachelors             13   \n",
              "\n",
              "        marital_status          occupation    relationship    race      sex  \\\n",
              "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
              "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
              "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
              "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
              "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
              "\n",
              "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
              "0          2174             0              40   United-States   <=50K  \n",
              "1             0             0              13   United-States   <=50K  \n",
              "2             0             0              40   United-States   <=50K  \n",
              "3             0             0              40   United-States   <=50K  \n",
              "4             0             0              40            Cuba   <=50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85bab523-fcc3-41a8-9e48-3a6a85154238\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85bab523-fcc3-41a8-9e48-3a6a85154238')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85bab523-fcc3-41a8-9e48-3a6a85154238 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85bab523-fcc3-41a8-9e48-3a6a85154238');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52c7e510-1c26-471e-b191-7561d952c3a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52c7e510-1c26-471e-b191-7561d952c3a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52c7e510-1c26-471e-b191-7561d952c3a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 32561,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 17,\n        \"max\": 90,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          28,\n          73,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \" Without-pay\",\n          \" Self-emp-not-inc\",\n          \" ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105549,\n        \"min\": 12285,\n        \"max\": 1484705,\n        \"num_unique_values\": 21648,\n        \"samples\": [\n          128485,\n          469907,\n          235951\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" Bachelors\",\n          \" HS-grad\",\n          \" Some-college\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          13,\n          9,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \" Never-married\",\n          \" Married-civ-spouse\",\n          \" Married-AF-spouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \" Machine-op-inspct\",\n          \" ?\",\n          \" Adm-clerical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \" Not-in-family\",\n          \" Husband\",\n          \" Other-relative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" Black\",\n          \" Other\",\n          \" Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Female\",\n          \" Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7385,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          3781,\n          15831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 402,\n        \"min\": 0,\n        \"max\": 4356,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          419,\n          2051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours_per_week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 99,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          6,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native_country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \" El-Salvador\",\n          \" Philippines\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" >50K\",\n          \" <=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Categorical Columns and Missing Values\n",
        "\n",
        "By choosing the columns in our dataset that have the {object} dtype, which typically denotes string values in a pandas DataFrame, we have been able to identify the category columns. We must quantitatively encode the qualitative input in these columns so that our machine learning models can process it.\n",
        "\n",
        "We address missing values inside these columns after identifying them. The most prevalent value, or mode, for each categorical column is used to fill in any missing values. This is a standard procedure that permits us to keep rows with missing data without adding undue bias. We make sure that our models won't come across nulls, which could potentially lead to mistakes during training, by filling in the missing data.\n",
        "\n"
      ],
      "metadata": {
        "id": "czf0G0xG6O5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying categorical columns\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# filling missing values with the mode for each categorical column\n",
        "for column in categorical_columns:\n",
        "    df[column].fillna(df[column].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "id": "t0ts1dB0-iiC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning and Preprocessing for Model Training\n",
        "\n",
        "Placeholder items in the dataset, such as '?', may indicate missing values. Here, we use `numpy} for the `NaN} definition and replace such placeholders with `NaN} to standardize missing value representation.\n",
        "\n",
        "\n",
        "We reevaluate the dataset for missing values after replacing placeholders. We restate the method for categorical columns, which is to use the mode to fill in any missing values. This validates that our DataFrame is clear and prepared for additional handling.\n",
        "\n",
        "After missing value management, we concentrate on categorical variable encoding. We use `OneHotEncoder` from `sklearn.preprocessing} to accomplish this. By using one-hot encoding, categorical data are transformed into a format that machine learning algorithms may use to make more accurate predictions. In order to prevent multicollinearity, we decide to discard the first level of each category characteristic.\n",
        "\n",
        "Following encoding, the altered categorical characteristics are contained in a new DataFrame called {encoded_df}. Next, we add the newly encoded variables to our dataset and remove the old categories columns.\n",
        "\n",
        "After cleaning and preprocessing our dataset, we can go on to the next stage, which is dividing it into training and test sets before training our machine learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "B1LLK9e86fRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replacing the placeholders like '?' with NaN for missing values\n",
        "df.replace('?', np.NaN, inplace=True)\n",
        "\n",
        "# Checking again for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Choosing a strategy to handle missing values, for example:\n",
        "# df.dropna(inplace=True) - This will drop all rows with any NaN values\n",
        "# or Fill missing values with mode for categorical columns\n",
        "for column in categorical_columns:\n",
        "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "\n",
        "# encoding the categorical variables\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Initializing the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "\n",
        "# Selecting categorical columns and fit the encoder\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "encoded_data = encoder.fit_transform(df[categorical_columns])\n",
        "\n",
        "# Creating a DataFrame with the encoded variables\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Dropping original categorical columns and concatenate the encoded ones\n",
        "df = df.drop(categorical_columns, axis=1)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# df is ready for splitting into train and test sets and then for model training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX4VDnep9y4i",
        "outputId": "5de48fd3-bdeb-411d-cafa-aee7f9cd511c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying Dataset Columns\n",
        "\n",
        "Following the preprocessing and encoding of categorical variables, it is crucial to confirm that our DataFrame is structured correctly. The names of the columns in our now-transformed dataset are printed out in this phase. By doing this, we make sure that our dataset is prepared for the next phases of machine learning model development and that all anticipated changes have been implemented successfully.\n",
        "\n"
      ],
      "metadata": {
        "id": "lj1VhGRd69za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhk-q1lc_X4-",
        "outputId": "d8a99bda-0894-45a1-a055-56c16f90cfff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss',\n",
            "       'hours_per_week', 'workclass_ Federal-gov', 'workclass_ Local-gov',\n",
            "       'workclass_ Never-worked', 'workclass_ Private',\n",
            "       ...\n",
            "       'native_country_ Puerto-Rico', 'native_country_ Scotland',\n",
            "       'native_country_ South', 'native_country_ Taiwan',\n",
            "       'native_country_ Thailand', 'native_country_ Trinadad&Tobago',\n",
            "       'native_country_ United-States', 'native_country_ Vietnam',\n",
            "       'native_country_ Yugoslavia', 'income_ >50K'],\n",
            "      dtype='object', length=101)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Data into Features and Target\n",
        "\n",
        "We separated our data into the characteristics and the target variable now that it is ready. The target variable, in this case `'income_ >50K'`, is the only column not included in the features (denoted as `X`). We pick this column as our target variable (`y`) because it indicates if an individual's income exceeds $50,000 annually.\n",
        "\n",
        "We are laying the groundwork for supervised learning, which aims to predict the target variable using the input features, by segmenting the dataset in this way. In order to ensure that our model can learn from one subset of the data and be evaluated on a subset, this step is essential for the following phase, which entails splitting the dataset into training and testing sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "pBrPSBrm7aLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into features and target\n",
        "X = df.drop('income_ >50K', axis=1)  # Make sure to use the correct column name\n",
        "y = df['income_ >50K']\n"
      ],
      "metadata": {
        "id": "qj5t0zRlAd6B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Training and Testing Sets\n",
        "\n",
        "By dividing our dataset into training and testing sets, we improve our data preparation procedure even more at this critical step. This separation enables our models to be trained on a subset of the data (the `training set`) and then assessed on a different subset (the `testing set`) to see how well they perform on data that hasn't been seen before. Here, `sklearn.model_selection`'s `train_test_split` function is utilized, with 20% of the data set aside for testing.\n",
        "\n",
        "We also make sure that the feature sets we use for testing and training are encoded consistently. One-Hot Encoding is used to accomplish this, converting categorical variables into a format that machine learning algorithms may use to ensure correct data interpretation. There is a chance that the training and testing sets will have different numbers of columns after encoding because one set may have more categorical variables than the other.\n",
        "\n",
        "In order to preserve consistency throughout our data, we align the training and testing sets to make sure they have the same columns. Ensuring that our models receive input data in a consistent format is a crucial step in the training and evaluation process.\n",
        "\n"
      ],
      "metadata": {
        "id": "WtgNOLJu73Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into features and target\n",
        "X = df.drop('income_ >50K', axis=1)  # Assuming 'income' is the target variable\n",
        "y = df['income_ >50K']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Applying One-Hot Encoding to the categorical variables in the feature set\n",
        "X_train_encoded = pd.get_dummies(X_train)\n",
        "X_test_encoded = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Making sure both training and testing sets have the same columns after encoding\n",
        "X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='inner', axis=1)\n",
        "\n",
        "# Now, X_train_encoded and X_test_encoded are ready for model training and evaluation\n"
      ],
      "metadata": {
        "id": "pjXEm8Z099yE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing the Naïve Bayes Classifier\n",
        "\n",
        "We start by getting our data ready, and then we use a machine learning technique to tackle the problem. First, we use the `GaussianNB` implementation of the Naïve Bayes classifier from `sklearn.naive_bayes`. Because of their ease of use, effectiveness, and frequently unexpectedly high performance—particularly in text classification problems—naïve Bayes models are widely used for classification tasks.\n",
        "\n",
        "Initially, we set the `GaussianNB` model to zero. In many cases, it makes sense to assume that the characteristics in this model have a normal distribution.\n",
        "\n",
        "Next, we use our encoded training datasets (`X_train_encoded` and `y_train`) to train the model. The `.fit()` method in scikit-learn is commonly used to train a model by providing the training data and the corresponding labels.\n",
        "\n",
        "Lastly, we make predictions on our test dataset (`X_test_encoded`) using the trained Naïve Bayes model. For this, a set of predictions is generated using the `.predict()` method, which is based on the features of the test set. The performance of the model will then be determined by comparing these predictions to the true labels (`y_test`).\n",
        "\n"
      ],
      "metadata": {
        "id": "FeAWLgC-8OO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize the Naïve Bayes model\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_classifier.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "nb_predictions = nb_classifier.predict(X_test_encoded)\n"
      ],
      "metadata": {
        "id": "LzTcxj-ADmKy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizing the Random Forest Classifier\n",
        "\n",
        "We now examine the Random Forest Classifier, a more sophisticated and generally more potent algorithm that builds on the framework created by the Naïve Bayes model. This model, which is a component of the `sklearn.ensemble` module, is well-known for its excellent accuracy, efficiency when processing big datasets, and adaptability to various classification problem types.\n",
        "\n",
        "To produce a prediction that is more reliable and accurate, the Random Forest method constructs several decision trees and then combines them. The robustness and effectiveness of the overall model are influenced by the variety among the individual trees, which are trained on various subsets of the dataset using a method known as bootstrap aggregating (or bagging).\n",
        "\n",
        "\n",
        "To guarantee the repeatability of our findings, we begin by initializing the `Random ForestClassifier` with a given `random_state`. We use our encoded training dataset to train the model after initialization. In order for the model to learn the correlations between the features and the target variable, it must be fitted to the data during the training step.\n",
        "\n",
        "We use the encoded test set to generate predictions once the model has been trained. As with the Naïve Bayes model evaluation, the Random Forest model's predictions will be compared to the true labels in order to assess its performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "-LygbBgT8yIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "rf_predictions = rf_classifier.predict(X_test_encoded)\n"
      ],
      "metadata": {
        "id": "NSiZyeUyDqIO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZVzdWLQj9R78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Evaluate Naïve Bayes\n",
        "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "print(\"Naïve Bayes Accuracy:\", nb_accuracy)\n",
        "print(classification_report(y_test, nb_predictions))\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(classification_report(y_test, rf_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwcGvG2fD0eo",
        "outputId": "08809dca-d928-40af-cee0-3b8648b5739d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Bayes Accuracy: 0.7990173499155535\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.95      0.88      4942\n",
            "         1.0       0.68      0.32      0.43      1571\n",
            "\n",
            "    accuracy                           0.80      6513\n",
            "   macro avg       0.75      0.64      0.66      6513\n",
            "weighted avg       0.78      0.80      0.77      6513\n",
            "\n",
            "Random Forest Accuracy: 0.8582834331337326\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.93      0.91      4942\n",
            "         1.0       0.74      0.63      0.68      1571\n",
            "\n",
            "    accuracy                           0.86      6513\n",
            "   macro avg       0.82      0.78      0.80      6513\n",
            "weighted avg       0.85      0.86      0.85      6513\n",
            "\n"
          ]
        }
      ]
    }
  ]
}